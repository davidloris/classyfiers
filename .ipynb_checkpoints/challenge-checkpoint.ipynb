{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#Reading the Train.CSV file. This file contains the entire features of the project but it is not certain \n",
    "# that inserting them all brings a better result in learning. For this reason there are other reading functions with less features\n",
    "\n",
    "\n",
    "#data = pd.read_csv('train.csv')\n",
    "data = pd.read_csv('train.csv')[[\"Gender\",\"Eye color\",\"Race\",\"Hair color\",\"Height\",\"Publisher\",\"Skin color\",\"Alignment\",\"Weight\",\"Agility\",\"Accelerated Healing\",\"Lantern Power Ring\",\"Dimensional Awareness\",\"Cold Resistance\",\"Durability\",\"Stealth\",\"Energy Absorption\",\"Flight\",\"Danger Sense\"]]\n",
    "#data = pd.read_csv('train.csv')[[\"Gender\",\"Race\",\"Height\",\"Publisher\",\"Alignment\",\"Weight\",\"Agility\",\"Accelerated Healing\",\"Lantern Power Ring\",\"Dimensional Awareness\",\"Cold Resistance\",\"Durability\",\"Stealth\",\"Energy Absorption\",\"Flight\",\"Danger Sense\"]]\n",
    "#data = pd.read_csv('train.csv')[[\"Race\",\"Hair color\",\"Height\",\"Skin color\",\"Alignment\",\"Weight\",\"Agility\",\"Accelerated Healing\",\"Lantern Power Ring\",\"Dimensional Awareness\",\"Cold Resistance\",\"Durability\",\"Stealth\",\"Energy Absorption\",\"Flight\",\"Danger Sense\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that is used to clean the data of our Dataset\n",
    "\n",
    "def clear_data(data):\n",
    "    \n",
    "    # With this command we transform all True False values to 0 or 1\n",
    "    data = data*1\n",
    "    \n",
    "    # Delete the Nan fields in the \"Gender\" column\n",
    "    y= data['Gender'].map({'Female': 0, 'Male': 1,np.nan:0.5})\n",
    "    #y= data['Gender'].map({'Female': 0, 'Male': 1,data[\"Gender\"].mean()})\n",
    "    \n",
    "    # I put to Nan all the negative values of height and weight. Then I replace the value\n",
    "    # Nan with the media\n",
    "    data[\"Height\"][data[\"Height\"] < 0] = np.nan\n",
    "    data[\"Height\"].fillna(data[\"Height\"].mean(), inplace=True)\n",
    "\n",
    "    data[\"Weight\"][data[\"Weight\"] < 0] = np.nan\n",
    "    data[\"Weight\"].fillna(data[\"Weight\"].mean(), inplace=True)\n",
    "    \n",
    "    #Errors in the names of various colors are corrected\n",
    "    data[\"Eye color\"] = np.where(data[\"Eye color\"] == 'bown',\"brown\",data[\"Eye color\"])\n",
    "    data[\"Hair color\"] = np.where(data[\"Hair color\"] == 'black',\"Black\",data[\"Hair color\"])\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method that insert the various values of the column on the columns\n",
    "def split_columns(name_column):\n",
    "    df = pd.DataFrame(data[name_column])\n",
    "    df = df.replace(np.nan, 'Prova')\n",
    "    df_pivot = df.pivot(columns=name_column, values=name_column)\n",
    "    df_pivot = df_pivot.replace(np.nan, 0)\n",
    "    df_pivot2 = df_pivot.where(df_pivot['Prova'] != 'Prova')\n",
    "    col = df_pivot2.columns\n",
    "    def f(x):\n",
    "        if type(x) == str:\n",
    "            return 1\n",
    "        else: \n",
    "            return x\n",
    "\n",
    "    for i in col:\n",
    "        df_pivot2[i] = df_pivot2[i].apply(f)\n",
    "\n",
    "    df_pivot2.drop('Prova', axis=1, inplace = True)\n",
    "    \n",
    "    df_pivot2.fillna(df_pivot2.mean(), inplace=True)\n",
    "    \n",
    "    data.drop(name_column, axis=1, inplace = True)\n",
    "    \n",
    "    data[df_pivot2.columns] = df_pivot2\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matteo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/matteo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#I clean our Dataset with the method previously created\n",
    "data = clear_data(data)\n",
    "\n",
    "#I take all the columns with the values ​​to Nan\n",
    "missing_values_index = missing_values_count[np.where(missing_values_count > 0, True, False)].index\n",
    "\n",
    "#For each value containing Nan data I use the \"split_columns\" method\n",
    "for i in missing_values_index:\n",
    "    split_columns(i)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I insert my Label inside, inside the X I insert the remaining table  \n",
    "\n",
    "y = data[\"Alignment\"]\n",
    "\n",
    "X = data.drop(columns=['Alignment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALORE FINALE METODO 1: 0.6585365853658537\n",
      "VALORE FINALE METODO 2: 0.6585365853658537\n",
      "VALORE METODO 3: 0.6585365853658537\n",
      "VALORE METODO 4: 0.6463414634146342\n",
      "VALORE METODO 5: 0.4878048780487805\n",
      "VALORE METODO 6: 0.6097560975609756\n",
      "VALORE METODO 7: 0.6951219512195121\n",
      "VALORE Naive-Bayes:  0.6585365853658537\n",
      "VALORE LinearSVC:  0.6951219512195121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matteo/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/matteo/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/matteo/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALORE Random Forest:  0.6951219512195121\n",
      "VALORE LogisticRegression:  0.6951219512195121\n",
      "############### Validation #############\n",
      "VALORE FINALE RANDOM FOREST:  0.7627118644067796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm,ensemble, tree, neighbors\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "X_train_scaler = scaler.fit_transform(X_train)\n",
    "X_test_scaler = scaler.fit_transform(X_test)\n",
    "\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_scaler, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train_scaler_final = scaler.fit_transform(X_train_final)\n",
    "X_test_scaler_final = scaler.fit_transform(X_val)\n",
    "\n",
    "#APPLY THE FIRST METHOD\n",
    "clf = svm.SVC(C = 10.0, gamma = 1e-5, random_state = 42)\n",
    "clf.fit(X_train_scaler_final, y_train_final) \n",
    "yhat = clf.predict(X_test_scaler_final)\n",
    "\n",
    "acc_val1 = metrics.accuracy_score(y_val,yhat)\n",
    "print(\"VALORE FINALE METODO 1:\",  acc_val1) \n",
    "\n",
    "#APPLY THE SECOND METHOD\n",
    "clf = svm.SVC(C=100.0,gamma = 1e-5,random_state=42)\n",
    "clf.fit(X_train_scaler_final, y_train_final) \n",
    "yhat = clf.predict(X_test_scaler_final)\n",
    "\n",
    "acc_val_2 = metrics.accuracy_score(y_val,yhat)\n",
    "print(\"VALORE FINALE METODO 2:\", acc_val_2)\n",
    "\n",
    "#APPLY THE THIRD METHOD\n",
    "clf = svm.SVC(C=1000.0,gamma = 1e-6,random_state=42)\n",
    "clf.fit(X_train_scaler_final, y_train_final) \n",
    "yhat = clf.predict(X_test_scaler_final)\n",
    "\n",
    "acc_val_3 = metrics.accuracy_score(y_val,yhat)\n",
    "print(\"VALORE METODO 3:\",acc_val_3)\n",
    "\n",
    "#APPLY THE FOURTH METHOD\n",
    "clf = ensemble.GradientBoostingClassifier(random_state=42)\n",
    "clf.fit(X_train_scaler_final, y_train_final) \n",
    "yhat = clf.predict(X_test_scaler_final)\n",
    "\n",
    "acc_val_4 = metrics.accuracy_score(y_val,yhat)\n",
    "print(\"VALORE METODO 4:\",acc_val_4)\n",
    "\n",
    "#APPLY THE FIFTH METHOD\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train_scaler_final, y_train_final) \n",
    "yhat = clf.predict(X_test_scaler_final)\n",
    "\n",
    "acc_val_4 = metrics.accuracy_score(y_val,yhat)\n",
    "print(\"VALORE METODO 5:\",acc_val_4)\n",
    "\n",
    "#APPLY THE SIXTH METHOD\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X_train_scaler_final, y_train_final) \n",
    "yhat = clf.predict(X_test_scaler_final)\n",
    "\n",
    "acc_val_4 = metrics.accuracy_score(y_val,yhat)\n",
    "print(\"VALORE METODO 6:\",acc_val_4)\n",
    "\n",
    "#APPLY THE SEVENTH METHOD\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "clf.fit(X_train_scaler_final, y_train_final) \n",
    "yhat = clf.predict(X_test_scaler_final)\n",
    "\n",
    "acc_val_4 = metrics.accuracy_score(y_val,yhat)\n",
    "print(\"VALORE METODO 7:\",acc_val_4)\n",
    "\n",
    "#################METHOD Naive-Bayes#############################\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gnb = GaussianNB()\n",
    "pred = gnb.fit(X_train_scaler_final, y_train_final).predict(X_test_scaler_final)\n",
    "print(\"VALORE Naive-Bayes: \",accuracy_score(y_val, pred, normalize = True))\n",
    "\n",
    "#############################################\n",
    "\n",
    "\n",
    "#################METHOD LinearSVC#############################\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svc_model = LinearSVC(random_state=42)\n",
    "#train the algorithm on training data and predict using the testing data\n",
    "pred = svc_model.fit(X_train_scaler_final, y_train_final).predict(X_test_scaler_final)\n",
    "#print the accuracy score of the model\n",
    "print(\"VALORE LinearSVC: \",accuracy_score(y_val, pred, normalize = True))\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "\n",
    "#############METHOD RandomForest#########################\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=3)    # n_estimators is number of Decision Tree in this algorithm.\n",
    "rf.fit(X_train_scaler_final, y_train_final.ravel())\n",
    "rf.predict(X_test_scaler_final)\n",
    "print(\"VALORE Random Forest: \",accuracy_score(y_val, pred, normalize = True))\n",
    "\n",
    "\n",
    "#######################################\n",
    "\n",
    "\n",
    "##################METHOD LogisticRegression######################\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaler_final, y_train_final)\n",
    "model.predict(X_test_scaler_final)\n",
    "print(\"VALORE LogisticRegression: \",accuracy_score(y_val, pred, normalize = True))\n",
    "########################################\n",
    "\n",
    "#IN THIS PART DAVO THEN TO VALIDATE THE VARIOUS MODELS THAT HAVE TAKEN A GREATER RESULT\n",
    "print(\"############### Validation #############\")\n",
    "#clf = ensemble.GradientBoostingClassifier(random_state=42)\n",
    "#clf.fit(X_train_scaler, y_train) \n",
    "#yhat = clf.predict(X_test_scaler)\n",
    "\n",
    "#acc3 = metrics.accuracy_score(y_test,yhat)\n",
    "#print(\"VALORE FINALE METODO 4:\",acc3)\n",
    "\n",
    "#clf = neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "#clf.fit(X_train_scaler, y_train) \n",
    "#yhat = clf.predict(X_test_scaler)\n",
    "\n",
    "#acc3 = metrics.accuracy_score(y_test,yhat)\n",
    "#print(\"VALORE FINALE METODO 7:\",acc3)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=3)    # n_estimators is number of Decision Tree in this algorithm.\n",
    "rf.fit(X_train_scaler, y_train.ravel())\n",
    "pred = rf.predict(X_test_scaler)\n",
    "print(\"VALORE FINALE RANDOM FOREST: \",accuracy_score(y_test, pred, normalize = True))\n",
    "\n",
    "\n",
    "\n",
    "#model = LogisticRegression()\n",
    "#model.fit(X_train_scaler, y_train)\n",
    "#pred = model.predict(X_test_scaler)\n",
    "#print(\"LogisticRegression Algorithm test accuracy: \",accuracy_score(y_test, pred, normalize = True))\n",
    "\n",
    "\n",
    "\n",
    "#svc_model = LinearSVC(random_state=42)\n",
    "#pred = svc_model.fit(X_train_scaler, y_train).predict(X_test_scaler)\n",
    "#print(\"LinearSVC accuracy : \",accuracy_score(y_test, pred, normalize = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
